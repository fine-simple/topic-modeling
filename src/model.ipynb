{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Int64Index: 37000 entries, 0 to 37044\n",
      "Series name: content\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "37000 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 578.1+ KB\n",
      "None\n",
      "0    WASHINGTON  —   Congressional Republicans have...\n",
      "1    After the bullet shells get counted, the blood...\n",
      "2    When Walt Disney’s “Bambi” opened in 1942, cri...\n",
      "3    Death may be the great equalizer, but it isn’t...\n",
      "4    SEOUL, South Korea  —   North Korea’s leader, ...\n",
      "Name: content, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "data = data[\"content\"].drop_duplicates().dropna()[:37000]\n",
    "print(data.info())\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/tawfik/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    WASHINGTON Congressional Republicans new fear ...\n",
      "1    bullet shells get counted blood dries votive c...\n",
      "2    Walt Disney Bambi opened 1942 critics praised ...\n",
      "3    Death may great equalizer necessarily evenhand...\n",
      "4    SEOUL South Korea North Korea leader Kim said ...\n",
      "Name: content, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# function to remove stopwords\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "def remove_stopwords(text : str):\n",
    "    textArr = tokenizer.tokenize(text)\n",
    "    rem_text = \" \".join([word for word in textArr if word.lower() not in stop_words ])\n",
    "    return rem_text\n",
    "\n",
    "# remove stopwords from the text\n",
    "data=data.apply(remove_stopwords)\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from gensim import corpora\n",
    "\n",
    "# nlp = en_core_web_sm.load()\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "def lemmatization(texts,allowed_postags=['NOUN', 'ADJ']): \n",
    "       output = []\n",
    "       for sent in texts:\n",
    "             doc = nlp(sent) \n",
    "             output.append([token.lemma_ for token in doc if token.pos_ in allowed_postags ])\n",
    "       return output\n",
    "tokenized_reviews = lemmatization(data.tolist())\n",
    "\n",
    "# print number of tokenization\n",
    "from importlib.util import find_spec as isModule\n",
    "if(isModule('humanize') != None):\n",
    "      from humanize import intword\n",
    "      print(intword(sum(len(x) for x in tokenized_reviews)), \" Tokenizations\")\n",
    "else:\n",
    "      print(sum(len(x) for x in tokenized_reviews), \" Tokenizations\")\n",
    "\n",
    "print(tokenized_reviews[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.8 million  Tokenizations\n",
      "[[(0, 1), (1, 9), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 2), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 4), (15, 6), (16, 3), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 2), (24, 1), (25, 1), (26, 1), (27, 1), (28, 2), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 5), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 11), (59, 1), (60, 1), (61, 1), (62, 1), (63, 5), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 2), (72, 1), (73, 3), (74, 1), (75, 1), (76, 2), (77, 1), (78, 1), (79, 1), (80, 2), (81, 1), (82, 1), (83, 1), (84, 1), (85, 1), (86, 2), (87, 2), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 2), (96, 1), (97, 1), (98, 1), (99, 2), (100, 2), (101, 1), (102, 1), (103, 1), (104, 2), (105, 1), (106, 1), (107, 2), (108, 1), (109, 2), (110, 1), (111, 1), (112, 1), (113, 1), (114, 2), (115, 1), (116, 1), (117, 5), (118, 1), (119, 2), (120, 1), (121, 1), (122, 1), (123, 3), (124, 1), (125, 1), (126, 3), (127, 1), (128, 2), (129, 2), (130, 1), (131, 1), (132, 1), (133, 1), (134, 1), (135, 1)], [(0, 1), (2, 1), (8, 1), (16, 11), (22, 1), (29, 2), (32, 1), (42, 1), (44, 1), (46, 2), (51, 2), (52, 2), (68, 1), (69, 8), (70, 2), (71, 1), (72, 1), (73, 1), (81, 4), (85, 2), (86, 4), (87, 5), (90, 3), (92, 16), (94, 3), (102, 2), (122, 1), (125, 4), (136, 1), (137, 1), (138, 1), (139, 1), (140, 1), (141, 1), (142, 1), (143, 1), (144, 1), (145, 1), (146, 1), (147, 1), (148, 2), (149, 4), (150, 3), (151, 2), (152, 2), (153, 1), (154, 1), (155, 1), (156, 1), (157, 1), (158, 2), (159, 1), (160, 2), (161, 1), (162, 1), (163, 1), (164, 1), (165, 1), (166, 1), (167, 1), (168, 1), (169, 3), (170, 1), (171, 2), (172, 2), (173, 3), (174, 4), (175, 3), (176, 3), (177, 1), (178, 1), (179, 1), (180, 1), (181, 1), (182, 1), (183, 7), (184, 2), (185, 1), (186, 1), (187, 1), (188, 1), (189, 1), (190, 1), (191, 1), (192, 1), (193, 2), (194, 1), (195, 1), (196, 1), (197, 1), (198, 1), (199, 2), (200, 7), (201, 3), (202, 1), (203, 1), (204, 1), (205, 2), (206, 1), (207, 1), (208, 1), (209, 1), (210, 1), (211, 2), (212, 1), (213, 6), (214, 10), (215, 1), (216, 1), (217, 1), (218, 1), (219, 1), (220, 1), (221, 2), (222, 1), (223, 1), (224, 2), (225, 1), (226, 1), (227, 1), (228, 1), (229, 1), (230, 1), (231, 1), (232, 1), (233, 1), (234, 1), (235, 2), (236, 18), (237, 1), (238, 1), (239, 2), (240, 1), (241, 1), (242, 1), (243, 1), (244, 4), (245, 7), (246, 1), (247, 1), (248, 3), (249, 1), (250, 5), (251, 2), (252, 2), (253, 1), (254, 26), (255, 1), (256, 1), (257, 1), (258, 1), (259, 2), (260, 1), (261, 3), (262, 1), (263, 1), (264, 1), (265, 8), (266, 1), (267, 2), (268, 12), (269, 2), (270, 2), (271, 1), (272, 3), (273, 1), (274, 1), (275, 1), (276, 1), (277, 1), (278, 1), (279, 1), (280, 3), (281, 5), (282, 1), (283, 1), (284, 1), (285, 1), (286, 6), (287, 1), (288, 1), (289, 1), (290, 1), (291, 1), (292, 1), (293, 4), (294, 3), (295, 1), (296, 2), (297, 1), (298, 1), (299, 7), (300, 1), (301, 1), (302, 1), (303, 1), (304, 1), (305, 1), (306, 1), (307, 1), (308, 1), (309, 2), (310, 3), (311, 1), (312, 1), (313, 1), (314, 1), (315, 1), (316, 3), (317, 1), (318, 1), (319, 1), (320, 1), (321, 2), (322, 1), (323, 2), (324, 1), (325, 1), (326, 5), (327, 3), (328, 1), (329, 1), (330, 3), (331, 2), (332, 1), (333, 3), (334, 2), (335, 4), (336, 1), (337, 1), (338, 1), (339, 1), (340, 1), (341, 1), (342, 1), (343, 1), (344, 1), (345, 1), (346, 1), (347, 1), (348, 1), (349, 1), (350, 1), (351, 1), (352, 3), (353, 1), (354, 2), (355, 3), (356, 1), (357, 1), (358, 2), (359, 2), (360, 1), (361, 1), (362, 1), (363, 1), (364, 1), (365, 1), (366, 1), (367, 1), (368, 1), (369, 1), (370, 3), (371, 1), (372, 1), (373, 2), (374, 1), (375, 1), (376, 2), (377, 1), (378, 2), (379, 13), (380, 1), (381, 1), (382, 1), (383, 1), (384, 2), (385, 2), (386, 1), (387, 1), (388, 1), (389, 1), (390, 1), (391, 1), (392, 3), (393, 2), (394, 1), (395, 12), (396, 1), (397, 2), (398, 3), (399, 2), (400, 1), (401, 10), (402, 1), (403, 3), (404, 3), (405, 1), (406, 26), (407, 2), (408, 1), (409, 1), (410, 1), (411, 1), (412, 4), (413, 1), (414, 1), (415, 1), (416, 2), (417, 1), (418, 1), (419, 1), (420, 2), (421, 1), (422, 1), (423, 1), (424, 1), (425, 1), (426, 1), (427, 11), (428, 1), (429, 1), (430, 1), (431, 1), (432, 1), (433, 2), (434, 1), (435, 2), (436, 20), (437, 2), (438, 1), (439, 2), (440, 1), (441, 25), (442, 1), (443, 1), (444, 1), (445, 1), (446, 1), (447, 1), (448, 1), (449, 1), (450, 1), (451, 3), (452, 1), (453, 1), (454, 1), (455, 1), (456, 2), (457, 1), (458, 3), (459, 1), (460, 5), (461, 1), (462, 1), (463, 3), (464, 1), (465, 1), (466, 1), (467, 1), (468, 1), (469, 1), (470, 1), (471, 5), (472, 4), (473, 1), (474, 2), (475, 2), (476, 1), (477, 4), (478, 1), (479, 1), (480, 1), (481, 2), (482, 1), (483, 1), (484, 3), (485, 3), (486, 1), (487, 1), (488, 1), (489, 1), (490, 1), (491, 1), (492, 1), (493, 2), (494, 1), (495, 1), (496, 1), (497, 1), (498, 2), (499, 3), (500, 1), (501, 1), (502, 2), (503, 1), (504, 3), (505, 1), (506, 1), (507, 1), (508, 1), (509, 2), (510, 1), (511, 3), (512, 2), (513, 1), (514, 3), (515, 1), (516, 3), (517, 1), (518, 1), (519, 8), (520, 1), (521, 2), (522, 1), (523, 1), (524, 1), (525, 4), (526, 1), (527, 1), (528, 2), (529, 1), (530, 1), (531, 3), (532, 1), (533, 1), (534, 1), (535, 1), (536, 1), (537, 1), (538, 2), (539, 3), (540, 1), (541, 1), (542, 1), (543, 2), (544, 1), (545, 1), (546, 1), (547, 1), (548, 1), (549, 2), (550, 1), (551, 1), (552, 2), (553, 1), (554, 1), (555, 1), (556, 1), (557, 1), (558, 1), (559, 1), (560, 1), (561, 2), (562, 1), (563, 2), (564, 1), (565, 1), (566, 1), (567, 1), (568, 2), (569, 1), (570, 1), (571, 1), (572, 1), (573, 1), (574, 1), (575, 2), (576, 1), (577, 3), (578, 1), (579, 1), (580, 1), (581, 1), (582, 1), (583, 5), (584, 4), (585, 3), (586, 9), (587, 1), (588, 1), (589, 1), (590, 1), (591, 1), (592, 3), (593, 1), (594, 1), (595, 2), (596, 2), (597, 1), (598, 1), (599, 4), (600, 1), (601, 1), (602, 5), (603, 1), (604, 3), (605, 1), (606, 1), (607, 2), (608, 12), (609, 1), (610, 8)]]\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(tokenized_reviews)\n",
    "\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in tokenized_reviews]\n",
    "\n",
    "print(doc_term_matrix[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/tawfik/semester/NLP/Project/src/model.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tawfik/semester/NLP/Project/src/model.ipynb#ch0000008?line=2'>3</a>\u001b[0m Lda \u001b[39m=\u001b[39m gensim\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mLdaMulticore\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tawfik/semester/NLP/Project/src/model.ipynb#ch0000008?line=4'>5</a>\u001b[0m \u001b[39m# Running and Trainign LDA model on the document term matrix.\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/tawfik/semester/NLP/Project/src/model.ipynb#ch0000008?line=5'>6</a>\u001b[0m ldamodel \u001b[39m=\u001b[39m Lda(corpus\u001b[39m=\u001b[39;49mdoc_term_matrix, id2word\u001b[39m=\u001b[39;49mdictionary, num_topics\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m, passes\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tawfik/semester/NLP/Project/src/model.ipynb#ch0000008?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m10\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mTopics\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, ldamodel\u001b[39m.\u001b[39mprint_topics(num_words\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m))\n",
      "File \u001b[0;32m~/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamulticore.py:186\u001b[0m, in \u001b[0;36mLdaMulticore.__init__\u001b[0;34m(self, corpus, num_topics, id2word, workers, chunksize, passes, batch, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, random_state, minimum_probability, minimum_phi_value, per_word_topics, dtype)\u001b[0m\n\u001b[1;32m    <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamulticore.py?line=182'>183</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(alpha, \u001b[39mstr\u001b[39m) \u001b[39mand\u001b[39;00m alpha \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamulticore.py?line=183'>184</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mauto-tuning alpha not implemented in LdaMulticore; use plain LdaModel.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamulticore.py?line=185'>186</a>\u001b[0m \u001b[39msuper\u001b[39;49m(LdaMulticore, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamulticore.py?line=186'>187</a>\u001b[0m     corpus\u001b[39m=\u001b[39;49mcorpus, num_topics\u001b[39m=\u001b[39;49mnum_topics,\n\u001b[1;32m    <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamulticore.py?line=187'>188</a>\u001b[0m     id2word\u001b[39m=\u001b[39;49mid2word, chunksize\u001b[39m=\u001b[39;49mchunksize, passes\u001b[39m=\u001b[39;49mpasses, alpha\u001b[39m=\u001b[39;49malpha, eta\u001b[39m=\u001b[39;49meta,\n\u001b[1;32m    <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamulticore.py?line=188'>189</a>\u001b[0m     decay\u001b[39m=\u001b[39;49mdecay, offset\u001b[39m=\u001b[39;49moffset, eval_every\u001b[39m=\u001b[39;49meval_every, iterations\u001b[39m=\u001b[39;49miterations,\n\u001b[1;32m    <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamulticore.py?line=189'>190</a>\u001b[0m     gamma_threshold\u001b[39m=\u001b[39;49mgamma_threshold, random_state\u001b[39m=\u001b[39;49mrandom_state, minimum_probability\u001b[39m=\u001b[39;49mminimum_probability,\n\u001b[1;32m    <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamulticore.py?line=190'>191</a>\u001b[0m     minimum_phi_value\u001b[39m=\u001b[39;49mminimum_phi_value, per_word_topics\u001b[39m=\u001b[39;49mper_word_topics, dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamulticore.py?line=191'>192</a>\u001b[0m )\n",
      "File \u001b[0;32m~/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamodel.py:520\u001b[0m, in \u001b[0;36mLdaModel.__init__\u001b[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[1;32m    <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamodel.py?line=517'>518</a>\u001b[0m use_numpy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatcher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamodel.py?line=518'>519</a>\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamodel.py?line=519'>520</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate(corpus, chunks_as_numpy\u001b[39m=\u001b[39;49muse_numpy)\n\u001b[1;32m    <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamodel.py?line=520'>521</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_lifecycle_event(\n\u001b[1;32m    <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamodel.py?line=521'>522</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcreated\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamodel.py?line=522'>523</a>\u001b[0m     msg\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrained \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m in \u001b[39m\u001b[39m{\u001b[39;00mtime\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamodel.py?line=523'>524</a>\u001b[0m )\n",
      "File \u001b[0;32m~/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamulticore.py:316\u001b[0m, in \u001b[0;36mLdaMulticore.update\u001b[0;34m(self, corpus, chunks_as_numpy)\u001b[0m\n\u001b[1;32m    <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamulticore.py?line=311'>312</a>\u001b[0m \u001b[39m# endfor single corpus pass\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamulticore.py?line=312'>313</a>\u001b[0m \n\u001b[1;32m    <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamulticore.py?line=313'>314</a>\u001b[0m \u001b[39m# wait for all outstanding jobs to finish\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamulticore.py?line=314'>315</a>\u001b[0m \u001b[39mwhile\u001b[39;00m queue_size[\u001b[39m0\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamulticore.py?line=315'>316</a>\u001b[0m     process_result_queue(force\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamulticore.py?line=317'>318</a>\u001b[0m \u001b[39mif\u001b[39;00m reallen \u001b[39m!=\u001b[39m lencorpus:\n\u001b[1;32m    <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamulticore.py?line=318'>319</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39minput corpus size changed during training (don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt use generators as input)\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamulticore.py:283\u001b[0m, in \u001b[0;36mLdaMulticore.update.<locals>.process_result_queue\u001b[0;34m(force)\u001b[0m\n\u001b[1;32m    <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamulticore.py?line=280'>281</a>\u001b[0m other\u001b[39m.\u001b[39mreset()\n\u001b[1;32m    <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamulticore.py?line=281'>282</a>\u001b[0m \u001b[39mif\u001b[39;00m eval_every \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m (force \u001b[39mor\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_updates \u001b[39m/\u001b[39m updateafter) \u001b[39m%\u001b[39m eval_every \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[0;32m--> <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamulticore.py?line=282'>283</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlog_perplexity(chunk, total_docs\u001b[39m=\u001b[39;49mlencorpus)\n",
      "File \u001b[0;32m~/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamodel.py:846\u001b[0m, in \u001b[0;36mLdaModel.log_perplexity\u001b[0;34m(self, chunk, total_docs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamodel.py?line=843'>844</a>\u001b[0m corpus_words \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(cnt \u001b[39mfor\u001b[39;00m document \u001b[39min\u001b[39;00m chunk \u001b[39mfor\u001b[39;00m _, cnt \u001b[39min\u001b[39;00m document)\n\u001b[1;32m    <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamodel.py?line=844'>845</a>\u001b[0m subsample_ratio \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m*\u001b[39m total_docs \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(chunk)\n\u001b[0;32m--> <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamodel.py?line=845'>846</a>\u001b[0m perwordbound \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbound(chunk, subsample_ratio\u001b[39m=\u001b[39;49msubsample_ratio) \u001b[39m/\u001b[39m (subsample_ratio \u001b[39m*\u001b[39m corpus_words)\n\u001b[1;32m    <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamodel.py?line=846'>847</a>\u001b[0m logger\u001b[39m.\u001b[39minfo(\n\u001b[1;32m    <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamodel.py?line=847'>848</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m per-word bound, \u001b[39m\u001b[39m%.1f\u001b[39;00m\u001b[39m perplexity estimate based on a held-out corpus of \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m documents with \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m words\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamodel.py?line=848'>849</a>\u001b[0m     perwordbound, np\u001b[39m.\u001b[39mexp2(\u001b[39m-\u001b[39mperwordbound), \u001b[39mlen\u001b[39m(chunk), corpus_words\n\u001b[1;32m    <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamodel.py?line=849'>850</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamodel.py?line=850'>851</a>\u001b[0m \u001b[39mreturn\u001b[39;00m perwordbound\n",
      "File \u001b[0;32m~/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamodel.py:1112\u001b[0m, in \u001b[0;36mLdaModel.bound\u001b[0;34m(self, corpus, gamma, subsample_ratio)\u001b[0m\n\u001b[1;32m   <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamodel.py?line=1109'>1110</a>\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mbound: at document #\u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m\"\u001b[39m, d)\n\u001b[1;32m   <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamodel.py?line=1110'>1111</a>\u001b[0m \u001b[39mif\u001b[39;00m gamma \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamodel.py?line=1111'>1112</a>\u001b[0m     gammad, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minference([doc])\n\u001b[1;32m   <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamodel.py?line=1112'>1113</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamodel.py?line=1113'>1114</a>\u001b[0m     gammad \u001b[39m=\u001b[39m gamma[d]\n",
      "File \u001b[0;32m~/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamodel.py:720\u001b[0m, in \u001b[0;36mLdaModel.inference\u001b[0;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[1;32m    <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamodel.py?line=717'>718</a>\u001b[0m gammad \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malpha \u001b[39m+\u001b[39m expElogthetad \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mdot(cts \u001b[39m/\u001b[39m phinorm, expElogbetad\u001b[39m.\u001b[39mT)\n\u001b[1;32m    <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamodel.py?line=718'>719</a>\u001b[0m Elogthetad \u001b[39m=\u001b[39m dirichlet_expectation(gammad)\n\u001b[0;32m--> <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamodel.py?line=719'>720</a>\u001b[0m expElogthetad \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexp(Elogthetad)\n\u001b[1;32m    <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamodel.py?line=720'>721</a>\u001b[0m phinorm \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(expElogthetad, expElogbetad) \u001b[39m+\u001b[39m epsilon\n\u001b[1;32m    <a href='file:///home/tawfik/.local/share/miniconda3/envs/nlp/lib/python3.9/site-packages/gensim/models/ldamodel.py?line=721'>722</a>\u001b[0m \u001b[39m# If gamma hasn't changed much, we're done.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "# Creating the object for LDA model using gensim library\n",
    "Lda = gensim.models.LdaMulticore\n",
    "\n",
    "# Running and Trainign LDA model on the document term matrix.\n",
    "ldamodel = Lda(corpus=doc_term_matrix, id2word=dictionary, num_topics=30, passes=10)\n",
    "print(\"-\"*10, \"\\n\", \"Topics\\n\", ldamodel.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nPerplexity: ', ldamodel.log_perplexity(doc_term_matrix,total_docs=len(data.index)))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "coherence_model_lda = CoherenceModel(model=ldamodel, texts=tokenized_reviews, dictionary=dictionary , coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "%matplotlib inline\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(ldamodel, doc_term_matrix, dictionary)\n",
    "vis"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b7cc8be550cdf44c314344ab531193bc730f6280e2dd1f0a5a13c73011f0b44"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
