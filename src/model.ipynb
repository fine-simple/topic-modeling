{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Int64Index: 37000 entries, 0 to 37044\n",
      "Series name: content\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "37000 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 578.1+ KB\n",
      "None\n",
      "0    WASHINGTON  —   Congressional Republicans have...\n",
      "1    After the bullet shells get counted, the blood...\n",
      "2    When Walt Disney’s “Bambi” opened in 1942, cri...\n",
      "3    Death may be the great equalizer, but it isn’t...\n",
      "4    SEOUL, South Korea  —   North Korea’s leader, ...\n",
      "Name: content, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "data = data[\"content\"].drop_duplicates().dropna()[:37000]\n",
    "print(data.info())\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\eslam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\eslam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    new fear comes health care lawsuit might The i...\n",
      "1    bullet get blood votive burn people peer see c...\n",
      "2    Walt visual vastly different anything done kno...\n",
      "3    may great necessarily endeavor mortal consider...\n",
      "4    South Kim said Sunday country making final con...\n",
      "Name: content, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')\n",
    "\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "corp = set(nltk.corpus.words.words())\n",
    "\n",
    "# function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    textArr = text.split(' ')\n",
    "    rem_text = \" \".join([word for word in textArr if word not in stop_words and word in corp])\n",
    "    return rem_text\n",
    "\n",
    "# remove stopwords from the text\n",
    "data=data.apply(remove_stopwords)\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from gensim import corpora\n",
    "\n",
    "# nlp = en_core_web_sm.load()\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "def lemmatization(texts,allowed_postags=['NOUN', 'ADJ']): \n",
    "       output = []\n",
    "       for sent in texts:\n",
    "             doc = nlp(sent) \n",
    "             output.append([token.lemma_ for token in doc if token.pos_ in allowed_postags ])\n",
    "       return output\n",
    "tokenized_reviews = lemmatization(data.tolist())\n",
    "\n",
    "print(tokenized_reviews[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print number of tokenization\n",
    "from importlib.util import find_spec as isModule\n",
    "if(isModule('humanize') != None):\n",
    "      from humanize import intword\n",
    "      print(intword(sum(len(x) for x in tokenized_reviews)), \" Tokenizations\")\n",
    "else:\n",
    "      print(sum(len(x) for x in tokenized_reviews), \" Tokenizations\")\n",
    "\n",
    "dictionary = corpora.Dictionary(tokenized_reviews)\n",
    "\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in tokenized_reviews]\n",
    "\n",
    "print(doc_term_matrix[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- \n",
      " Topics\n",
      " [(12, '0.029*\"company\" + 0.015*\"business\" + 0.012*\"border\" + 0.011*\"new\" + 0.009*\"mexican\" + 0.008*\"executive\" + 0.008*\"financial\" + 0.007*\"chief\" + 0.007*\"food\" + 0.007*\"money\"'), (19, '0.036*\"immigration\" + 0.024*\"illegal\" + 0.020*\"order\" + 0.018*\"executive\" + 0.015*\"government\" + 0.013*\"country\" + 0.013*\"border\" + 0.012*\"administration\" + 0.012*\"ban\" + 0.011*\"new\"'), (5, '0.024*\"white\" + 0.019*\"people\" + 0.017*\"black\" + 0.013*\"man\" + 0.010*\"gay\" + 0.008*\"social\" + 0.007*\"actor\" + 0.007*\"time\" + 0.006*\"film\" + 0.005*\"woman\"'), (24, '0.053*\"police\" + 0.034*\"gun\" + 0.026*\"people\" + 0.014*\"law\" + 0.012*\"violence\" + 0.010*\"enforcement\" + 0.010*\"city\" + 0.009*\"fire\" + 0.009*\"man\" + 0.008*\"protest\"'), (11, '0.042*\"percent\" + 0.015*\"poll\" + 0.013*\"game\" + 0.013*\"last\" + 0.013*\"first\" + 0.012*\"team\" + 0.010*\"second\" + 0.009*\"good\" + 0.009*\"time\" + 0.008*\"final\"'), (10, '0.017*\"political\" + 0.014*\"man\" + 0.011*\"government\" + 0.010*\"many\" + 0.009*\"people\" + 0.007*\"power\" + 0.006*\"public\" + 0.006*\"opposition\" + 0.005*\"group\" + 0.005*\"history\"'), (16, '0.024*\"attack\" + 0.021*\"people\" + 0.013*\"terrorist\" + 0.012*\"security\" + 0.012*\"police\" + 0.011*\"military\" + 0.011*\"group\" + 0.010*\"government\" + 0.010*\"man\" + 0.009*\"terror\"'), (17, '0.016*\"people\" + 0.013*\"percent\" + 0.013*\"water\" + 0.012*\"health\" + 0.012*\"high\" + 0.010*\"medical\" + 0.009*\"study\" + 0.008*\"school\" + 0.008*\"many\" + 0.007*\"state\"'), (1, '0.027*\"court\" + 0.023*\"federal\" + 0.020*\"case\" + 0.019*\"law\" + 0.015*\"state\" + 0.013*\"legal\" + 0.011*\"judge\" + 0.010*\"abortion\" + 0.008*\"decision\" + 0.008*\"death\"'), (8, '0.021*\"people\" + 0.011*\"virus\" + 0.010*\"many\" + 0.009*\"sexual\" + 0.009*\"religious\" + 0.008*\"sex\" + 0.008*\"man\" + 0.008*\"public\" + 0.007*\"new\" + 0.006*\"human\"'), (21, '0.035*\"medium\" + 0.022*\"news\" + 0.013*\"social\" + 0.011*\"people\" + 0.010*\"press\" + 0.010*\"story\" + 0.008*\"article\" + 0.008*\"political\" + 0.008*\"new\" + 0.008*\"reporter\"'), (2, '0.018*\"russian\" + 0.018*\"former\" + 0.015*\"intelligence\" + 0.013*\"investigation\" + 0.011*\"administration\" + 0.011*\"information\" + 0.011*\"campaign\" + 0.010*\"security\" + 0.009*\"official\" + 0.008*\"government\"'), (4, '0.046*\"nuclear\" + 0.031*\"military\" + 0.028*\"missile\" + 0.028*\"korean\" + 0.021*\"south\" + 0.013*\"defense\" + 0.013*\"chinese\" + 0.012*\"test\" + 0.010*\"ballistic\" + 0.009*\"new\"'), (0, '0.051*\"police\" + 0.029*\"man\" + 0.017*\"officer\" + 0.011*\"report\" + 0.010*\"crime\" + 0.009*\"car\" + 0.009*\"woman\" + 0.009*\"sexual\" + 0.008*\"video\" + 0.008*\"criminal\"'), (9, '0.016*\"new\" + 0.008*\"people\" + 0.007*\"many\" + 0.006*\"technology\" + 0.006*\"art\" + 0.006*\"work\" + 0.006*\"space\" + 0.006*\"time\" + 0.005*\"way\" + 0.005*\"city\"'), (15, '0.027*\"people\" + 0.019*\"trade\" + 0.018*\"american\" + 0.014*\"economic\" + 0.011*\"european\" + 0.011*\"country\" + 0.011*\"good\" + 0.011*\"world\" + 0.008*\"many\" + 0.008*\"political\"'), (3, '0.033*\"campaign\" + 0.015*\"presidential\" + 0.014*\"party\" + 0.014*\"political\" + 0.011*\"support\" + 0.010*\"candidate\" + 0.009*\"former\" + 0.008*\"conservative\" + 0.008*\"election\" + 0.007*\"primary\"'), (7, '0.026*\"music\" + 0.017*\"film\" + 0.017*\"song\" + 0.015*\"singer\" + 0.013*\"video\" + 0.011*\"band\" + 0.011*\"new\" + 0.011*\"album\" + 0.010*\"pop\" + 0.009*\"first\"'), (20, '0.025*\"child\" + 0.023*\"girl\" + 0.015*\"brain\" + 0.015*\"dog\" + 0.013*\"boy\" + 0.013*\"mother\" + 0.009*\"photo\" + 0.009*\"woman\" + 0.008*\"daughter\" + 0.008*\"people\"'), (13, '0.017*\"money\" + 0.012*\"percent\" + 0.011*\"olympic\" + 0.010*\"sport\" + 0.010*\"labor\" + 0.010*\"wage\" + 0.010*\"work\" + 0.009*\"many\" + 0.009*\"gold\" + 0.009*\"foreign\"')]\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "# Creating the object for LDA model using gensim library\n",
    "Lda = gensim.models.LdaMulticore\n",
    "\n",
    "# Running and Trainign LDA model on the document term matrix.\n",
    "ldamodel = Lda(corpus=doc_term_matrix, id2word=dictionary, num_topics=30, passes=10)\n",
    "print(\"-\"*10, \"\\n\", \"Topics\\n\", ldamodel.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nPerplexity: ', ldamodel.log_perplexity(doc_term_matrix,total_docs=len(data.index)))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "coherence_model_lda = CoherenceModel(model=ldamodel, texts=tokenized_reviews, dictionary=dictionary , coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "%matplotlib inline\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(ldamodel, doc_term_matrix, dictionary)\n",
    "vis"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
